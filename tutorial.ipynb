{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks w/ MNIST\n",
    "As an introduction to neural networks and deep learning, we will cover the beginner friendly MNIST data set, which is widely used as an initial tutorial for many courses. MNIST is very easy; the data set is virtually completely clean, meaning there does not have to be any stress with data processing. All we have to do is create and train a simple neural network that can recognize the handwritten digits of the data set. We will be using the Keras library, making it a breeze to program.\n",
    "<img src=\"https://www.researchgate.net/profile/Steven_Young11/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's MNIST?\n",
    "\n",
    "\"The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments.[5] Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.\"\n",
    "\n",
    "You can think of it like the \"Hello World\" of computer vision. Its a collection of 28 by 28 images of handwritten numbers, totalling around 60,000 training images and 10,000 testing images. We will use this to create a simple neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks?\n",
    "Neural networks are like any other supervised machine learning models—they take in an input and pushes out a desirable output through the process of labeled training. They are roughly compared to how neurons transmit signal (like I said it's a very rough analogy). They are considerably more complex than most other machine learning models, but they are relatively easy to program nowadays because of libraries. In the case of MLPs (multlayered perceptrons) AKA simple neural networks, there is an input, hidden, and output layers: \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/280px-Colored_neural_network.svg.png\">\n",
    "\n",
    "The structure of the network and its layers are often referred to as its network **architecture** or **topology**. This layered format and process of passing data through is what distinguishes neural networks from most other algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example in MNIST\n",
    "For MNIST, you can imagine the layout of the network being something like this: \n",
    "\n",
    "<img src=\"https://ml4a.github.io/images/figures/mnist_1layer.png\">\n",
    "\n",
    "—where the input layers takes in the flattened version of the 28 by 28 images (total 784 pixels per image) and transmits the data across its hidden layers where the magic is done. The input nodes are greyscale values of each pixels. And in the end of it all, it'll reach the output layer comprising of ten nodes, each representing the 10 digits (from 0 to 9). The general rule of thumb is that we ignore the inner mathematical operations that are taking place in the hidden layers, we only care about the outputs being right. Don't worry about knowing how the magic trick works at the moment, you can watch <a href=\"https://youtu.be/aircAruvnKk\">3B1B's detailed explanation playlist on YouTube</a> regarding this topic (specifically the MNIST example). Remember to not get caught up on the maths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Lab\n",
    "\n",
    "I don't really want to explain and lecture stuff anymore because I believe it's pretty confusing and unhelpful for many of you. I think it's for the best we give you hands on activities like what we did last meeting so you'll gain valuable skills. AI is a broad topic and I want to get into the interesting parts quicker, like ConvNets and reinforcement learning, so I'm believing in you to be self-reliant.\n",
    "Anyways, your job is to take each code segment and explain what it does in a separate ipynb (Jupyter Notebook file). Copy each of the code segments below and add a separate markdown block above explaining what the code section does.\n",
    "\n",
    "Resources to research from:\n",
    "https://www.tensorflow.org/tutorials/keras/classification,\n",
    "https://github.com/wxs/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb,\n",
    "https://victorzhou.com/blog/keras-neural-network-tutorial/,\n",
    "https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(i):\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "imshow(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')   # to float\n",
    "test_images = test_images.astype('float32')\n",
    "train_images /= 255  # normalize\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # initialize   \n",
    "model.add(Flatten(input_shape=(28, 28)))   # add layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2567 - accuracy: 0.9275\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1132 - accuracy: 0.9675\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0782 - accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0578 - accuracy: 0.9827\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0453 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0345 - accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0291 - accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0191 - accuracy: 0.9942\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0154 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16cf2e1cf88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07980159235574538\n",
      "Test accuracy: 0.9787999987602234\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
